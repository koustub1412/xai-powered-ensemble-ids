{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8850d10e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "X_train shape: (125973, 80)\n",
      "Classes: [0 1 2 3]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import joblib\n",
    "\n",
    "from sklearn.metrics import accuracy_score, classification_report, f1_score\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Input\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "RANDOM_STATE = 42\n",
    "\n",
    "print(\"Loading data...\")\n",
    "X_train = np.load(\"../data/processed/X_train.npy\")\n",
    "X_test = np.load(\"../data/processed/X_test.npy\")\n",
    "y_train = np.load(\"../data/processed/y_train.npy\")\n",
    "y_test = np.load(\"../data/processed/y_test.npy\")\n",
    "\n",
    "print(\"X_train shape:\", X_train.shape)\n",
    "print(\"Classes:\", np.unique(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8e1c70a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Custom Amplified Weights: {0: 0.46765439615104765, 1: 0.685724083872232, 2: 3.5124592484557313, 3: 52.639147564469916}\n"
     ]
    }
   ],
   "source": [
    "# 1. Bring back YOUR brilliant amplified weights\n",
    "classes = np.unique(y_train)\n",
    "weights_array = compute_class_weight('balanced', classes=classes, y=y_train)\n",
    "custom_weights = dict(zip(classes, weights_array))\n",
    "\n",
    "# Amplify minority classes for Probe and Privilege\n",
    "custom_weights[2] *= 1.3\n",
    "custom_weights[3] *= 1.75\n",
    "\n",
    "# Fix for Keras: ensure keys are native Python ints\n",
    "keras_weights = {int(k): float(v) for k, v in custom_weights.items()}\n",
    "print(f\"Using Custom Amplified Weights: {keras_weights}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2b1b41db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generating OOF meta-features...\n",
      "Training base model 1/4 (KNeighborsClassifier)...\n",
      "Training base model 2/4 (DecisionTreeClassifier)...\n",
      "Training base model 3/4 (LogisticRegression)...\n",
      "Training base model 4/4 (RandomForestClassifier)...\n",
      "OOF Feature Generation Complete in 2.02 minutes.\n"
     ]
    }
   ],
   "source": [
    "# 2. Fast Base Models Setup\n",
    "knn_stack = KNeighborsClassifier(n_neighbors=7, weights='distance', n_jobs=-1)\n",
    "\n",
    "dt_stack = DecisionTreeClassifier(\n",
    "    max_depth=None, min_samples_split=8, min_samples_leaf=2,\n",
    "    class_weight=custom_weights, random_state=RANDOM_STATE\n",
    ")\n",
    "\n",
    "lr_stack = LogisticRegression(\n",
    "    max_iter=1000, solver='lbfgs', class_weight=custom_weights, random_state=RANDOM_STATE\n",
    ")\n",
    "\n",
    "rf_stack = RandomForestClassifier(\n",
    "    n_estimators=400, min_samples_split=3, min_samples_leaf=1,\n",
    "    max_features='sqrt', class_weight=custom_weights, random_state=RANDOM_STATE, n_jobs=-1\n",
    ")\n",
    "\n",
    "models = [knn_stack, dt_stack, lr_stack, rf_stack]\n",
    "\n",
    "# 3. Fast OOF Generation\n",
    "print(\"\\nGenerating OOF meta-features...\")\n",
    "start_time = time.time()\n",
    "\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=RANDOM_STATE)\n",
    "n_classes = len(classes)\n",
    "n_models = len(models)\n",
    "\n",
    "X_meta_train = np.zeros((X_train.shape[0], n_models * n_classes))\n",
    "X_meta_test = np.zeros((X_test.shape[0], n_models * n_classes))\n",
    "\n",
    "for i, model in enumerate(models):\n",
    "    print(f\"Training base model {i+1}/{n_models} ({model.__class__.__name__})...\")\n",
    "    meta_test_fold = np.zeros((X_test.shape[0], n_classes))\n",
    "\n",
    "    for train_idx, val_idx in skf.split(X_train, y_train):\n",
    "        X_tr, X_val = X_train[train_idx], X_train[val_idx]\n",
    "        y_tr = y_train[train_idx]\n",
    "\n",
    "        model.fit(X_tr, y_tr)\n",
    "        X_meta_train[val_idx, i*n_classes:(i+1)*n_classes] = model.predict_proba(X_val)\n",
    "        meta_test_fold += model.predict_proba(X_test)\n",
    "\n",
    "    X_meta_test[:, i*n_classes:(i+1)*n_classes] = meta_test_fold / skf.n_splits\n",
    "\n",
    "print(f\"OOF Feature Generation Complete in {(time.time() - start_time)/60:.2f} minutes.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f163b89c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Meta-Learner (Keras Neural Network)...\n",
      "Meta-Learner training complete.\n"
     ]
    }
   ],
   "source": [
    "# 4. Your Proven Keras Meta-Learner\n",
    "print(\"\\nTraining Meta-Learner (Keras Neural Network)...\")\n",
    "\n",
    "y_train_cat = to_categorical(y_train)\n",
    "y_test_cat = to_categorical(y_test)\n",
    "\n",
    "meta_model = Sequential([\n",
    "    Input(shape=(X_meta_train.shape[1],)), # Warning fix applied here\n",
    "    Dense(128, activation='relu'),\n",
    "    Dropout(0.35),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dropout(0.25),\n",
    "    Dense(n_classes, activation='softmax')\n",
    "])\n",
    "\n",
    "meta_model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "# Train Keras with the amplified weights\n",
    "meta_model.fit(\n",
    "    X_meta_train, \n",
    "    y_train_cat, \n",
    "    epochs=35, \n",
    "    batch_size=128, \n",
    "    validation_split=0.2, \n",
    "    class_weight=keras_weights, \n",
    "    verbose=0 \n",
    ")\n",
    "print(\"Meta-Learner training complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "bdb266b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== ULTIMATE HYBRID RESULTS (BASELINE) =====\n",
      "Accuracy:  0.82310\n",
      "Macro F1:  0.76849\n",
      "\n",
      "Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.97      0.84      9711\n",
      "           1       0.96      0.83      0.89      7458\n",
      "           2       0.84      0.76      0.80      2421\n",
      "           3       0.95      0.39      0.55      2954\n",
      "\n",
      "    accuracy                           0.82     22544\n",
      "   macro avg       0.87      0.73      0.77     22544\n",
      "weighted avg       0.85      0.82      0.81     22544\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 5. Initial Evaluation (Standard argmax)\n",
    "print(\"\\n===== ULTIMATE HYBRID RESULTS (BASELINE) =====\")\n",
    "\n",
    "y_pred_proba = meta_model.predict(X_meta_test, verbose=0)\n",
    "y_pred_meta = np.argmax(y_pred_proba, axis=1)\n",
    "\n",
    "acc = accuracy_score(y_test, y_pred_meta)\n",
    "macro_f1 = f1_score(y_test, y_pred_meta, average='macro')\n",
    "\n",
    "print(f\"Accuracy:  {acc:.5f}\")\n",
    "print(f\"Macro F1:  {macro_f1:.5f}\")\n",
    "print(\"\\nClassification Report:\\n\")\n",
    "print(classification_report(y_test, y_pred_meta))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "4cf75643",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== AUTOMATED THRESHOLD FINDER (NO DATA LEAKAGE) =====\n",
      "üî• Optimal Class 3 Multiplier Found: 1.0\n",
      "Validation Accuracy with this multiplier: 0.99714\n",
      "Maximized Validation Class 3 F1: 0.87500\n"
     ]
    }
   ],
   "source": [
    "# 6. Automated Threshold Finder (CLEAN VALIDATION SET METHOD)\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "import numpy as np\n",
    "\n",
    "print(\"\\n===== AUTOMATED THRESHOLD FINDER (NO DATA LEAKAGE) =====\")\n",
    "\n",
    "# 1. Extract the exact 20% validation set that Keras used during training\n",
    "val_size = int(len(X_meta_train) * 0.2)\n",
    "X_meta_val = X_meta_train[-val_size:]\n",
    "y_val = y_train[-val_size:]\n",
    "\n",
    "# 2. Predict on the VALIDATION set, NOT the Test set\n",
    "y_pred_proba_val = meta_model.predict(X_meta_val, verbose=0)\n",
    "\n",
    "best_class3_f1 = 0\n",
    "best_multiplier = 1.0\n",
    "best_report = None\n",
    "best_acc = 0\n",
    "\n",
    "# Test multipliers from 1.0 to 15.0 in steps of 0.5\n",
    "for mult in np.arange(1.0, 15.5, 0.5):\n",
    "    temp_proba = y_pred_proba_val.copy()\n",
    "    \n",
    "    # Boost Class 3\n",
    "    temp_proba[:, 3] *= mult \n",
    "    \n",
    "    temp_pred = np.argmax(temp_proba, axis=1)\n",
    "    \n",
    "    report_dict = classification_report(y_val, temp_pred, output_dict=True, zero_division=0)\n",
    "    current_class3_f1 = report_dict['3']['f1-score']\n",
    "    \n",
    "    if current_class3_f1 > best_class3_f1:\n",
    "        best_class3_f1 = current_class3_f1\n",
    "        best_multiplier = mult\n",
    "        best_report = classification_report(y_val, temp_pred, zero_division=0)\n",
    "        best_acc = accuracy_score(y_val, temp_pred)\n",
    "\n",
    "print(f\"üî• Optimal Class 3 Multiplier Found: {best_multiplier}\")\n",
    "print(f\"Validation Accuracy with this multiplier: {best_acc:.5f}\")\n",
    "print(f\"Maximized Validation Class 3 F1: {best_class3_f1:.5f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "263b934f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Optimal Clean Threshold (1.0x) saved successfully!\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "joblib.dump({'class_3_multiplier': best_multiplier}, \"../outputs/models/optimal_thresholds.pkl\")\n",
    "print(f\"‚úÖ Optimal Clean Threshold ({best_multiplier}x) saved successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34048342",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'# 7. Saving the Winning Pipeline\\nimport joblib\\n\\nprint(\"\\n===== SAVING WINNING PIPELINE =====\")\\n\\n# Save the Keras Meta-Learner\\nmeta_model.save(\"../outputs/models/meta_model_ultimate.keras\")\\nprint(\"‚úÖ Keras Meta-Learner saved successfully!\")\\n\\n# Save the Base Models \\njoblib.dump(models, \"../outputs/models/fast_base_models.pkl\")\\nprint(\"‚úÖ Fast Base Models saved successfully!\")\\n\\n# Save your custom weights \\njoblib.dump(custom_weights, \"../outputs/models/ultimate_class_weights.pkl\")\\nprint(\"‚úÖ Custom Amplified Weights saved successfully!\")\\n\\n\\nprint(\"\\nüèÜ Notebook 03 Complete. Ready for Explainability.\")'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''# 7. Saving the Winning Pipeline\n",
    "import joblib\n",
    "\n",
    "print(\"\\n===== SAVING WINNING PIPELINE =====\")\n",
    "\n",
    "# Save the Keras Meta-Learner\n",
    "meta_model.save(\"../outputs/models/meta_model_ultimate.keras\")\n",
    "print(\"‚úÖ Keras Meta-Learner saved successfully!\")\n",
    "\n",
    "# Save the Base Models \n",
    "joblib.dump(models, \"../outputs/models/fast_base_models.pkl\")\n",
    "print(\"‚úÖ Fast Base Models saved successfully!\")\n",
    "\n",
    "# Save your custom weights \n",
    "joblib.dump(custom_weights, \"../outputs/models/ultimate_class_weights.pkl\")\n",
    "print(\"‚úÖ Custom Amplified Weights saved successfully!\")\n",
    "\n",
    "\n",
    "print(\"\\nüèÜ Notebook 03 Complete. Ready for Explainability.\")'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
